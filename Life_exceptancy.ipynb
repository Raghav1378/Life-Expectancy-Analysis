{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2b6f9-1c37-40e7-9447-e09e94c78a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224f887-f006-4257-9820-0b33e0c1291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Life Expectancy Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632e920-af8f-4529-8bd9-98daacc836b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62eaef-8193-44a6-ade7-aa487435f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad48a9e-47f9-49ac-9dd4-53709b5c4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98c91f-3e44-48ba-bbf3-d4bf88d49f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bd6ed-4ca2-49ef-b278-5c743aa6b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5a12b-3617-469d-98e4-80d941ad44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d04773-7438-4c50-8d1f-eceeec899a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc51cd-b41d-48b5-93db-6f8bc4b28d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df,x=df['Status'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03182041-7325-4991-9315-4e80b2f0ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=df['Status'],y=df['Life expectancy '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5736a-052d-4663-9242-d2e38df0cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=df['Status'],y=df['infant deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c7531-3c6d-4ed5-b997-8c66493329ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.lineplot(data=df,x=df[' BMI '],y=df['infant deaths'])\n",
    "plt.title('BMI vs Infant Deaths')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('infantDied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455541f-4662-4407-b78a-808324e19e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_relation(df, x_col, y_col, kind='line', figsize=(10, 6)):\n",
    "  \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if kind == 'scatter':\n",
    "        sns.scatterplot(data=df, x=x_col, y=y_col,ci=None)\n",
    "    elif kind == 'line':\n",
    "        sns.lineplot(data=df, x=x_col, y=y_col)\n",
    "    elif kind == 'reg':\n",
    "        sns.regplot(data=df, x=x_col, y=y_col, line_kws={\"color\": \"red\"})\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'scatter', 'line', or 'reg'\")\n",
    "    \n",
    "    plt.title(f'{x_col} vs {y_col}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c9873-d138-4113-96d7-a1d23333fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    " # now df is correct\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0a1fa-3b05-405f-82b0-ae5d13eba8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relation(df,x_col=' BMI ',y_col='Life expectancy ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a184b7a-ae80-4784-80bf-a4c54e44c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max BMI:\", df[' BMI '].max())\n",
    "print(\"Min BMI:\", df[' BMI '].min())\n",
    "print(df[' BMI '].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b202dc6-1874-48b0-9ccb-8bfa1df43551",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relation(df,x_col=df['Alcohol'],y_col=df['Life expectancy '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151dc746-59da-454a-8823-15a0c1dd0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)['Life expectancy '].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1d664-05e7-4c18-8545-b56d339069b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74a06f-4e97-43b2-a0aa-dab43267965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b847b97-4879-494e-bfeb-e595dc6012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a4dd2-4f44-4ce1-85af-604f8848b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Step 2: Loop through columns and impute based on skewness\n",
    "for col in num_df.columns:\n",
    "    if num_df[col].isnull().sum() > 0:\n",
    "        skew_val = num_df[col].skew()\n",
    "        strategy = 'median' if abs(skew_val) > 0.5 else 'mean'\n",
    "        \n",
    "        imputer = SimpleImputer(strategy=strategy)\n",
    "        df[[col]] = imputer.fit_transform(num_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72237a9a-2267-4436-8cbc-e8b753c6ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af8b35-2560-4e7e-9aa0-a568d0989ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_vs_life(df, feature, target='Life expectancy '):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.regplot(x=df[feature], y=df[target], scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "    plt.title(f'{feature} vs {target}', fontsize=14)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(target)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc9b26-9554-41c7-8395-6fd8013d8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_vs_life(df, 'Hepatitis B')\n",
    "plot_feature_vs_life(df, 'Alcohol')\n",
    "plot_feature_vs_life(df, 'GDP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b68aa-a11f-4a52-9316-f1e48c27f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "sm.qqplot(df['Alcohol'], line='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1530c-e305-4e7f-a8b1-7897b508b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df,x='Year',y='Life expectancy ',ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6318c-1aec-4455-af13-b3b1264574f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Population', y='GDP', data=df)\n",
    "\n",
    "# Format x-axis with commas\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.gca().get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "plt.xlabel(\"Population\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.title(\"GDP vs Population\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ed12c-8ac3-4a87-b4c5-8c551ca46227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Population'].head(10))\n",
    "print(df['Population'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc78954-01d4-4e53-99c8-1bb5731ecef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df,x=df['Population'],y=df['GDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dac2f8-490e-421a-8b20-1454bbcea4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, column):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[column], kde=True, bins=30, color='skyblue')\n",
    "    plt.title(f'Distribution Plot for {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcc634-db69-45f7-a40f-791bd159fc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_df=df.drop(['Country','Year','Status'],axis=1)\n",
    "for col in temp_df.columns:\n",
    "    plot_distribution(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e2c1f-d9ff-4f2d-b608-de52dba4d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, column):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=df[column], color='orange')\n",
    "    plt.title(f'Boxplot for {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e50021-8869-4f81-8c5b-29144e6ed6fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in temp_df.columns:\n",
    "    plot_box(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d2f27-83a1-4e63-a4bb-64ebad3ecb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, x_col, y_col):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=df[x_col], y=df[y_col], hue=df[y_col], palette='viridis')\n",
    "    plt.title(f'Scatter Plot: {x_col} vs {y_col}')\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48d5fb-d341-45dd-bf58-a50f28b33d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "from itertools import combinations\n",
    "for x_col, y_col in combinations(numeric_df.columns, 2):\n",
    "    plot_scatter(numeric_df, x_col, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4ab9d-5a85-4e26-90ad-cf01a0a95ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(numeric_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf9e8f-57c2-432b-9188-67ff893eeae2",
   "metadata": {},
   "source": [
    "# Before SCaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba93a5-4500-44a6-8903-84c53e287f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b75903-9653-4485-9605-18e33afc68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Country','Status','Year'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a526916-dd69-4d54-be36-9781bcf94f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a49b2-63e8-41c1-8c5e-4a22533efcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Life expectancy '],axis=1)\n",
    "Y=df['Life expectancy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccb410-44aa-42c7-a7bf-0f043a0f5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4559917-05cd-4942-bccf-27bf8e941637",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    LinearRegression(): \"LinearRegression\",\n",
    "    DecisionTreeRegressor(max_depth=4): \"DecisionTreeRegressor\",\n",
    "    RandomForestRegressor(max_depth=4): \"RandomForestRegressor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6cc1a-ea09-441e-877a-c9a33490a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models: \n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred_train=model.predict(X_train)\n",
    "    Y_pred_test=model.predict(X_test)\n",
    "\n",
    "    print(f\"the r2 score of the model:{model} of the training   is\",r2_score(Y_train,Y_pred_train))\n",
    "    print(f\"the mae of the model {model} is of the training is\",mean_absolute_error(Y_train,Y_pred_train))\n",
    "    print(f\"the mse of the model {model} is of the training is \",mean_squared_error(Y_train,Y_pred_train))    \n",
    "    print('------------------')\n",
    "    print(f\"the r2 score of the model:{model} of the test   is\",r2_score(Y_test,Y_pred_test))\n",
    "    print(f\"the mae of the model {model} is of the test is\",mean_absolute_error(Y_test,Y_pred_test))\n",
    "    print(f\"the mse of the model {model} is of the test is \",mean_squared_error(Y_test,Y_pred_test))   \n",
    "\n",
    "    print('')\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9e5ff-1ce2-4c1f-8c36-4e036a674803",
   "metadata": {},
   "source": [
    "# SO after checking the model R2_score and teh mae we are going to use the VOTING REGRESSOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33acc4-7a51-4305-920f-0c2997a3dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingRegressor(estimators=[\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=4)),\n",
    "    ('RandomForestRegressor', RandomForestRegressor(max_depth=4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e578a-c252-4de1-bcf8-396685cf46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f643601-01c1-4422-babd-cacee7a2ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train_vc=vc.predict(X_train)\n",
    "Y_pred_test_vc=vc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951001e-6b83-46b6-93b1-1a4af52892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the r2 score of the model voting regsoor on the training   is\",r2_score(Y_train,Y_pred_train_vc))\n",
    "print(f\"the mae of the model voting regsoor on the training   is\",mean_absolute_error(Y_train,Y_pred_train_vc))\n",
    "print(f\"the mse of the model voting regsoor on the training   is\",mean_squared_error(Y_train,Y_pred_train_vc))    \n",
    "print('------------------')\n",
    "print(f\"the r2 score of themodel voting regsoor on the testing  is\",r2_score(Y_test,Y_pred_test_vc))\n",
    "print(f\"the mae of the model voting regsoor on the testing  is\",mean_absolute_error(Y_test,Y_pred_test_vc))\n",
    "print(f\"the mse of the model voting regsoor on the testing  is\",mean_squared_error(Y_test,Y_pred_test_vc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2586ac-f736-4e47-9b71-05148e11b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores1 = cross_val_score(vc, X, Y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R¬≤ for {scores1}: {scores1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd6741-6475-40c9-b6c2-6283fc0f42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde2249-6a9f-4f61-9153-76933187aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        \"max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"n_estimators\": [50, 100],\n",
    "        \"max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663745d-2b66-4b73-b320-a899e8a2d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d74e1-c911-4f9f-ba1b-96164d1cc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç Tuning and training: {name}\")\n",
    "    \n",
    "    if name in param_grids:\n",
    "        grid = GridSearchCV(model, param_grids[name], cv=5, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train, Y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(\"Best Params:\", grid.best_params_)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train)\n",
    "        best_model = model\n",
    "    \n",
    "    best_models[name] = best_model\n",
    "\n",
    "    # Predictions\n",
    "    Y_pred_train = best_model.predict(X_train)\n",
    "    Y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"Train R¬≤: {r2_score(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MAE: {mean_absolute_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MSE: {mean_squared_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print('------------------')\n",
    "    print(f\"Test R¬≤: {r2_score(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MAE: {mean_absolute_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MSE: {mean_squared_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3915e38-49e7-4a93-863d-8ede756c0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = DecisionTreeRegressor(max_depth=10, min_samples_split=5)\n",
    "best_rf = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=2)\n",
    "lr = LinearRegression()  \n",
    "\n",
    "\n",
    "vc2 = VotingRegressor(estimators=[\n",
    "    ('LinearRegression', lr),\n",
    "    ('DecisionTree', best_tree),\n",
    "    ('RandomForest', best_rf)\n",
    "])\n",
    "vc2.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_train_vc2 = vc2.predict(X_train)\n",
    "Y_pred_test_vc2 = vc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87c649-43da-444c-b523-46f4c231150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the r2 score of the model voting regsoor on the training   is\",r2_score(Y_train,Y_pred_train_vc2))\n",
    "print(f\"the mae of the model voting regsoor on the training   is\",mean_absolute_error(Y_train,Y_pred_train_vc2))\n",
    "print(f\"the mse of the model voting regsoor on the training   is\",mean_squared_error(Y_train,Y_pred_train_vc2))    \n",
    "print('------------------')\n",
    "print(f\"the r2 score of themodel voting regsoor on the testing  is\",r2_score(Y_test,Y_pred_test_vc2))\n",
    "print(f\"the mae of the model voting regsoor on the testing  is\",mean_absolute_error(Y_test,Y_pred_test_vc2))\n",
    "print(f\"the mse of the model voting regsoor on the testing  is\",mean_squared_error(Y_test,Y_pred_test_vc2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2737d50-d78e-4b30-b78a-3afff55000f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82754f02-3582-4b0c-9a27-b9dafc996747",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, Y, cv=5, scoring='r2')\n",
    "    print(f\"Cross-validated R¬≤ for {name}: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b7c9d-7917-4df0-b85a-af9abedb9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(max_depth=10, min_samples_split=10),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(max_depth=10, min_samples_split=2, n_estimators=100)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, Y, cv=5, scoring='r2')\n",
    "    print(f\"Cross-validated R¬≤ for {name}: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839a94e-c798-43c3-9ccb-2446d680a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(vc2, X, Y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R¬≤ for {scores2}: {scores2.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511cf60-e348-4944-8bd3-c0c98490aa0a",
   "metadata": {},
   "source": [
    "# Now we are going to scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ba869-30f8-4f0d-904f-e20058e40985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f833b-b7d9-404c-86f1-56cd409ef978",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48767026-a5ca-4bdb-8cc9-0947fe3afc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=sc.fit_transform(X_train)\n",
    "X_test_new=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfce57f-6730-413a-b0cc-1d6498e59be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=pd.DataFrame(X_train_new,columns=X.columns)\n",
    "X_test_new=pd.DataFrame(X_test_new,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41204e13-1cc4-4b54-970e-eee86d997a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    LinearRegression(): \"LinearRegression\",\n",
    "    DecisionTreeRegressor(max_depth=4): \"DecisionTreeRegressor\",\n",
    "    RandomForestRegressor(max_depth=4): \"RandomForestRegressor\"\n",
    "}\n",
    "for model in models: \n",
    "    model.fit(X_train_new,Y_train)\n",
    "    Y_pred_train=model.predict(X_train_new)\n",
    "    Y_pred_test=model.predict(X_test_new)\n",
    "\n",
    "    print(f\"the r2 score of the model:{model} of the training   is\",r2_score(Y_train,Y_pred_train))\n",
    "    print(f\"the mae of the model {model} is of the training is\",mean_absolute_error(Y_train,Y_pred_train))\n",
    "    print(f\"the mse of the model {model} is of the training is \",mean_squared_error(Y_train,Y_pred_train))    \n",
    "    print('------------------')\n",
    "    print(f\"the r2 score of the model:{model} of the test   is\",r2_score(Y_test,Y_pred_test))\n",
    "    print(f\"the mae of the model {model} is of the test is\",mean_absolute_error(Y_test,Y_pred_test))\n",
    "    print(f\"the mse of the model {model} is of the test is \",mean_squared_error(Y_test,Y_pred_test))   \n",
    "\n",
    "    print('')\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e4006-0083-435a-9059-4104b385b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = DecisionTreeRegressor(max_depth=10, min_samples_split=5)\n",
    "best_rf = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=2)\n",
    "lr = LinearRegression()  \n",
    "\n",
    "\n",
    "vc3 = VotingRegressor(estimators=[\n",
    "    ('LinearRegression', lr),\n",
    "    ('DecisionTree', best_tree),\n",
    "    ('RandomForest', best_rf)\n",
    "])\n",
    "vc3.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred_train_vc3 = vc3.predict(X_train_new)\n",
    "Y_pred_test_vc3 = vc3.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2ac08-1017-4a13-96c3-def5ac5c68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the r2 score of the model voting regsoor on the training   is\",r2_score(Y_train,Y_pred_train_vc3))\n",
    "print(f\"the mae of the model voting regsoor on the training   is\",mean_absolute_error(Y_train,Y_pred_train_vc3))\n",
    "print(f\"the mse of the model voting regsoor on the training   is\",mean_squared_error(Y_train,Y_pred_train_vc3))    \n",
    "print('------------------')\n",
    "print(f\"the r2 score of themodel voting regsoor on the testing  is\",r2_score(Y_test,Y_pred_test_vc2))\n",
    "print(f\"the mae of the model voting regsoor on the testing  is\",mean_absolute_error(Y_test,Y_pred_test_vc2))\n",
    "print(f\"the mse of the model voting regsoor on the testing  is\",mean_squared_error(Y_test,Y_pred_test_vc2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70cdd2-111b-42c4-a1d8-046995458798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "models = {\n",
    "    LinearRegression(): \"LinearRegression\",\n",
    "    DecisionTreeRegressor(max_depth=4): \"DecisionTreeRegressor\",\n",
    "    RandomForestRegressor(max_depth=4): \"RandomForestRegressor\"\n",
    "}\n",
    "\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train_new, Y_train)\n",
    "    fitted_models[models[model]] = model  \n",
    "    Y_pred_train = model.predict(X_train_new)\n",
    "    Y_pred_test = model.predict(X_test_new)\n",
    "\n",
    "    print(f\"--- {models[model]} ---\")\n",
    "    print(f\"Train R2: {r2_score(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MAE: {mean_absolute_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MSE: {mean_squared_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Test R2: {r2_score(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MAE: {mean_absolute_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MSE: {mean_squared_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print(\"----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d5e47-d25e-40c5-8b27-babadf27ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train_new.columns\n",
    "\n",
    "# Random Forest Regressor feature importances\n",
    "rfc = fitted_models['RandomForestRegressor']\n",
    "rfc_importances = pd.Series(rfc.feature_importances_, index=feature_names)\n",
    "rfc_importances.sort_values(ascending=False).plot(kind='bar', figsize=(12,6), title=\"Random Forest Feature Importances\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree Regressor feature importances\n",
    "dtc = fitted_models['DecisionTreeRegressor']\n",
    "dtc_importances = pd.Series(dtc.feature_importances_, index=feature_names)\n",
    "dtc_importances.sort_values(ascending=False).plot(kind='bar', figsize=(12,6), title=\"Decision Tree Feature Importances\", color='orange')\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf3c83-c1b9-4469-9e7e-dbad3487a8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41725ddc-a29c-4da2-9529-2345b29f81d5",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Thoughts and What I‚Äôve Learned\n",
    "\n",
    "After working on the Life Expectancy dataset, I‚Äôve gained a lot of insights into how different socio-economic and health factors contribute to how long people live in a country. This project wasn‚Äôt just about building models ‚Äî it helped me truly understand the data and its underlying patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç What I Understood from the Data\n",
    "\n",
    "- The dataset had quite a few **missing values**, and I learned how important it is to handle them wisely. I used **mean** or **median imputation** based on the skewness of each feature.\n",
    "- Scaling features using **StandardScaler** helped improve the performance of models like Linear Regression.\n",
    "- I noticed strong correlations and patterns between life expectancy and other variables ‚Äî especially **HIV/AIDS**, **Adult Mortality**, and **Income Composition of Resources**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Key Insights I Discovered\n",
    "\n",
    "- **HIV/AIDS rate** has one of the most negative impacts on life expectancy. Reducing its prevalence could dramatically improve a country‚Äôs life span.\n",
    "- **Income Composition of Resources** ‚Äî basically a measure of wealth distribution and access ‚Äî had a positive effect on life expectancy.\n",
    "- **Schooling** and **BMI** were also positively related to a longer life.\n",
    "- **Adult Mortality** is a very intuitive but powerful feature ‚Äî higher mortality means lower life expectancy.\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ My Model Building Journey\n",
    "\n",
    "I tried three different models:\n",
    "- Linear Regression\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "\n",
    "Then I combined them using a **Voting Regressor** to improve accuracy by blending their strengths. After testing both **scaled and unscaled data**, I got the best results with scaling.\n",
    "\n",
    "**Final Model (Voting Regressor - Scaled Data):**\n",
    "- **R¬≤ Score on Training Set**: ~0.89\n",
    "- **R¬≤ Score on Test Set**: ~0.87\n",
    "\n",
    "These results show that the model learned well and didn‚Äôt just memorize the training data.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What I Learned Overall\n",
    "\n",
    "- Ensemble models like **Random Forest** are quite powerful and reliable.\n",
    "- Handling missing data, scaling features, and understanding feature importance can drastically impact model performance.\n",
    "- **Data visualization** and **SHAP plots** helped me understand what the model was thinking and why it made certain predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° What I‚Äôd Like to Improve or Do Next\n",
    "\n",
    "- Explore more advanced models like **XGBoost** or **LightGBM**.\n",
    "- Fine-tune hyperparameters using **RandomizedSearchCV** or **GridSearchCV**.\n",
    "- Try **SHAP** (SHapley Additive exPlanations) for deeper interpretability of feature contributions.\n",
    "- Add external factors (like country-level policy indicators) to enrich the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "This project taught me a lot more than just how to build a machine learning model ‚Äî it helped me **connect data science to real-world outcomes**, especially in health and development. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a9cbc-3046-4953-9444-f5394d4583c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Prepare model list with names\n",
    "final_models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(max_depth=10, min_samples_split=5),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=2),\n",
    "    \"VotingRegressor\": vc3  # vc3 is already trained with scaled data\n",
    "}\n",
    "\n",
    "# Store results\n",
    "comparison_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    if name != \"VotingRegressor\":\n",
    "        model.fit(X_train_new, Y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train_new)\n",
    "    y_test_pred = model.predict(X_test_new)\n",
    "\n",
    "    comparison_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train R¬≤\": round(r2_score(Y_train, y_train_pred), 4),\n",
    "        \"Test R¬≤\": round(r2_score(Y_test, y_test_pred), 4),\n",
    "        \"Train MAE\": round(mean_absolute_error(Y_train, y_train_pred), 4),\n",
    "        \"Test MAE\": round(mean_absolute_error(Y_test, y_test_pred), 4),\n",
    "        \"Train MSE\": round(mean_squared_error(Y_train, y_train_pred), 4),\n",
    "        \"Test MSE\": round(mean_squared_error(Y_test, y_test_pred), 4)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.set_index(\"Model\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749d269-f84d-4eb9-997e-e50679a7db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bar plot for R¬≤ Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=comparison_df.index, y=comparison_df[\"Test R¬≤\"], palette=\"viridis\")\n",
    "plt.title(\"Model Comparison - Test R¬≤ Score\", fontsize=16)\n",
    "plt.ylabel(\"R¬≤ Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746114bb-c7d4-4f76-8072-daead6607348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both train and test R¬≤ in one graph\n",
    "comparison_df_plot = comparison_df[[\"Train R¬≤\", \"Test R¬≤\"]].reset_index().melt(id_vars=\"Model\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=comparison_df_plot, x=\"Model\", y=\"value\", hue=\"variable\", palette=\"Set2\")\n",
    "plt.title(\"Train vs Test R¬≤ Score Comparison\", fontsize=16)\n",
    "plt.ylabel(\"R¬≤ Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title=\"\")\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abc9fb-6b60-442a-9869-9b556827ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bc7d9-40d1-41ed-8171-c20aada90ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"SVR\":\n",
    "        model.fit(X_train_new, Y_train)\n",
    "        preds = model.predict(X_test_new)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "    mae = mean_absolute_error(Y_test, preds)\n",
    "    mse = mean_squared_error(Y_test, preds)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"R2 Score\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"R2 Score\", ascending=False)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e3e5e-3838-497b-92eb-4cc752e8d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_results[\"Model\"], df_results[\"R2 Score\"], color='skyblue')\n",
    "plt.xlabel(\"R2 Score\")\n",
    "plt.title(\"Model Comparison - R2 Score\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98314bfb-abbb-4656-b89b-5e181836f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your actual top 3 after printing df_results\n",
    "vr = VotingRegressor(estimators=[\n",
    "    ('xgb', XGBRegressor()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('gbr', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "vr.fit(X_train, Y_train)\n",
    "vr_preds = vr.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "r2_vr = r2_score(Y_test, vr_preds)\n",
    "mae_vr = mean_absolute_error(Y_test, vr_preds)\n",
    "mse_vr = mean_squared_error(Y_test, vr_preds)\n",
    "\n",
    "print(\"\\nVoting Regressor Performance:\")\n",
    "print(f\"R2 Score: {r2_vr:.4f}\")\n",
    "print(f\"MAE: {mae_vr:.4f}\")\n",
    "print(f\"MSE: {mse_vr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526fbfe-7876-4782-9f68-351539efc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(max_depth=4),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(max_depth=4),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(verbosity=0),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "# To store fitted models\n",
    "fitted_models = {}\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_new, Y_train)\n",
    "    fitted_models[name] = model\n",
    "\n",
    "    Y_pred_train = model.predict(X_train_new)\n",
    "    Y_pred_test = model.predict(X_test_new)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Train R2: {r2_score(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MAE: {mean_absolute_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Train MSE: {mean_squared_error(Y_train, Y_pred_train):.4f}\")\n",
    "    print(f\"Test R2: {r2_score(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MAE: {mean_absolute_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print(f\"Test MSE: {mean_squared_error(Y_test, Y_pred_test):.4f}\")\n",
    "    print(\"----------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8586bdc-2210-4fd8-9650-8e0b1eee9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models Voting Regressor (customize based on scores)\n",
    "voting_regressor = VotingRegressor([\n",
    "    ('rfr', fitted_models['RandomForestRegressor']),\n",
    "    ('xgbr', fitted_models['XGBRegressor']),\n",
    "    ('gbr', fitted_models['GradientBoostingRegressor']),\n",
    "    ('lr', fitted_models['LinearRegression'])\n",
    "])\n",
    "\n",
    "voting_regressor.fit(X_train_new, Y_train)\n",
    "\n",
    "# Predictions\n",
    "voting_train_pred = voting_regressor.predict(X_train_new)\n",
    "voting_test_pred = voting_regressor.predict(X_test_new)\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Voting Regressor ===\")\n",
    "print(f\"Train R2: {r2_score(Y_train, voting_train_pred):.4f}\")\n",
    "print(f\"Train MAE: {mean_absolute_error(Y_train, voting_train_pred):.4f}\")\n",
    "print(f\"Train MSE: {mean_squared_error(Y_train, voting_train_pred):.4f}\")\n",
    "print(f\"Test R2: {r2_score(Y_test, voting_test_pred):.4f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(Y_test, voting_test_pred):.4f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(Y_test, voting_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e9dfc-113e-45cb-8e50-a81a5003907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "xgb = XGBRegressor()\n",
    "rfr = RandomForestRegressor(max_depth=4)\n",
    "\n",
    "# Create Voting Regressor\n",
    "voting_reg = VotingRegressor(estimators=[\n",
    "    ('GBR', gbr),\n",
    "    ('XGB', xgb),\n",
    "    ('RFR', rfr)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "voting_reg.fit(X_train_new, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_pred_train = voting_reg.predict(X_train_new)\n",
    "Y_pred_test = voting_reg.predict(X_test_new)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"--- Voting Regressor ---\")\n",
    "print(f\"Train R2: {r2_score(Y_train, Y_pred_train):.4f}\")\n",
    "print(f\"Train MAE: {mean_absolute_error(Y_train, Y_pred_train):.4f}\")\n",
    "print(f\"Train MSE: {mean_squared_error(Y_train, Y_pred_train):.4f}\")\n",
    "print(f\"Test R2: {r2_score(Y_test, Y_pred_test):.4f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(Y_test, Y_pred_test):.4f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(Y_test, Y_pred_test):.4f}\")\n",
    "print(\"------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653df0d-6923-4e9a-b75f-a54f2bda582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for actual vs predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=Y_test, y=Y_pred_test, color='blue', alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Voting Regressor: Actual vs Predicted (Test Set)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182b8da-f5d1-4d84-a519-5039bbc35127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluation results (from your output)\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"LinearRegression\", \"DecisionTree\", \"RandomForest\", \n",
    "        \"GradientBoosting\", \"XGBoost\", \"SVR\"\n",
    "    ],\n",
    "    \"Train R2\": [0.8160, 0.8810, 0.9127, 0.9598, 0.9991, 0.8664],\n",
    "    \"Test R2\":  [0.8221, 0.8676, 0.9052, 0.9487, 0.9625, 0.8717],\n",
    "    \"Train MAE\": [3.0434, 2.4566, 2.0580, 1.3852, 0.1986, 2.3516],\n",
    "    \"Test MAE\":  [2.8607, 2.5309, 2.1178, 1.5368, 1.2173, 2.3087],\n",
    "    \"Train MSE\": [16.7967, 10.8670, 7.9679, 3.6684, 0.0832, 12.1982],\n",
    "    \"Test MSE\":  [15.4217, 11.4736, 8.2154, 4.4498, 3.2467, 11.1210]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Plotting R2 Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Model\", y=\"value\", hue=\"Metric\", \n",
    "            data=pd.melt(df, id_vars=\"Model\", value_vars=[\"Train R2\", \"Test R2\"], var_name=\"Metric\"))\n",
    "plt.title(\"R¬≤ Score Comparison\")\n",
    "plt.ylabel(\"R¬≤ Score\")\n",
    "plt.ylim(0.75, 1.05)\n",
    "plt.show()\n",
    "\n",
    "# Plotting MAE\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Model\", y=\"value\", hue=\"Metric\", \n",
    "            data=pd.melt(df, id_vars=\"Model\", value_vars=[\"Train MAE\", \"Test MAE\"], var_name=\"Metric\"))\n",
    "plt.title(\"Mean Absolute Error (MAE) Comparison\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Model\", y=\"value\", hue=\"Metric\", \n",
    "            data=pd.melt(df, id_vars=\"Model\", value_vars=[\"Train MSE\", \"Test MSE\"], var_name=\"Metric\"))\n",
    "plt.title(\"Mean Squared Error (MSE) Comparison\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e9159-082b-4d23-af44-5089a5ae7405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
